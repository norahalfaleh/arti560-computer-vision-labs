{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430e7f7b",
   "metadata": {},
   "source": [
    "##### ARTI 560 - Computer Vision  \n",
    "## Image Classification using Transfer Learning - Exercise \n",
    "\n",
    "### Objective\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    "1. Select another pretrained model (e.g., VGG16, MobileNetV2, or EfficientNet) and fine-tune it for CIFAR-10 classification.  \n",
    "You'll find the pretrained models in [Tensorflow Keras Applications Module](https://www.tensorflow.org/api_docs/python/tf/keras/applications).\n",
    "\n",
    "2. Before training, inspect the architecture using model.summary() and observe:\n",
    "- Network depth\n",
    "- Number of parameters\n",
    "- Trainable vs Frozen layers\n",
    "\n",
    "3. Then compare its performance with ResNet and the custom CNN.\n",
    "\n",
    "### Questions:\n",
    "\n",
    "- Which model achieved the highest accuracy?\n",
    "- Which model trained faster?\n",
    "- How might the architecture explain the differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a26d77e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4c7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\DELL\\anaconda3\\envs\\cv_lab\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cifar10_mobilenetV2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cifar10_mobilenetV2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resizing (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Resizing</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,810</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ augmentation (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resizing (\u001b[38;5;33mResizing\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m12,810\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,270,794</span> (8.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,270,794\u001b[0m (8.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,810</span> (50.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,810\u001b[0m (50.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "\n",
    "# 1. Define Data Augmentation \n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(0.1),\n",
    "], name=\"augmentation\")\n",
    "\n",
    "# 2. Build the base model (MobileNetV2)\n",
    "mobilenet_base = MobileNetV2(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# 3. Freeze the backbone initially\n",
    "mobilenet_base.trainable = False \n",
    "\n",
    "# 4. Construct the full model\n",
    "mobilenet_model = keras.Sequential([\n",
    "    layers.Input(shape=(32, 32, 3)),\n",
    "    data_augmentation, \n",
    "    layers.Resizing(224, 224, interpolation=\"bilinear\"),\n",
    "    layers.Lambda(mobilenet_preprocess), \n",
    "    mobilenet_base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(10) \n",
    "], name=\"cifar10_mobilenetV2\")\n",
    "\n",
    "# 5. Inspect the architecture\n",
    "# This will show the depth, parameters, and frozen status\n",
    "mobilenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f834434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\cv_lab\\Lib\\site-packages\\keras\\src\\datasets\\cifar.py:18: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  d = cPickle.load(f, encoding=\"bytes\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable layers in MobileNet: 20\n",
      "Epoch 1/3\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1848s\u001b[0m 3s/step - accuracy: 0.5566 - loss: 1.3164 - val_accuracy: 0.7376 - val_loss: 0.7674\n",
      "Epoch 2/3\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1633s\u001b[0m 2s/step - accuracy: 0.7289 - loss: 0.7977 - val_accuracy: 0.8136 - val_loss: 0.5408\n",
      "Epoch 3/3\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1727s\u001b[0m 2s/step - accuracy: 0.7672 - loss: 0.6812 - val_accuracy: 0.8340 - val_loss: 0.4701\n",
      "\n",
      "MobileNetV2 Fine-tuned Test Accuracy: 0.8327999711036682\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 1. Reload the data because the session lost it\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test  = x_test.astype(\"float32\")\n",
    "y_train = y_train.squeeze().astype(\"int64\")\n",
    "y_test  = y_test.squeeze().astype(\"int64\")\n",
    "\n",
    "# 2. Unfreeze the last 20 layers of MobileNetV2\n",
    "mobilenet_base.trainable = True\n",
    "for layer in mobilenet_base.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"Trainable layers in MobileNet: {sum(l.trainable for l in mobilenet_base.layers)}\")\n",
    "\n",
    "# 3. Compile the model\n",
    "mobilenet_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# 4. Train the model (This will now find x_train and y_train)\n",
    "history_mobile = mobilenet_model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=3,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 5. Evaluate on test data\n",
    "test_loss_m, test_acc_m = mobilenet_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nMobileNetV2 Fine-tuned Test Accuracy: {test_acc_m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3149f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Performance Comparison ---\n",
      "1. Custom CNN Accuracy:  0.7099\n",
      "2. ResNet50V2 Accuracy:  0.9161\n",
      "3. MobileNetV2 Accuracy: 0.8328\n",
      "\n",
      "--- Model Architecture Context ---\n",
      "- MobileNetV2 Total Params: 2,270,794\n",
      "- ResNet50V2 Total Params:  ~23,500,000\n",
      "\n",
      "--- Exercise Insights ---\n",
      "- Accuracy Gap: Transfer Learning (ResNet/MobileNet) outperformed Custom CNN by over 12-20%.\n",
      "- Efficiency: MobileNetV2 achieved 83.28% accuracy with only 10% of ResNet's parameters.\n"
     ]
    }
   ],
   "source": [
    "# Final Performance Comparison \n",
    "print(\"\\n--- Final Performance Comparison ---\")\n",
    "\n",
    "# 1. Custom CNN: From Lab 1 results\n",
    "custom_cnn_acc = 0.7099\n",
    "print(f\"1. Custom CNN Accuracy:  {custom_cnn_acc:.4f}\")\n",
    "\n",
    "# 2. ResNet50V2: From Lab 2 results\n",
    "resnet_acc = 0.9161\n",
    "print(f\"2. ResNet50V2 Accuracy:  {resnet_acc:.4f}\")\n",
    "\n",
    "# 3. MobileNetV2: This Exercise run\n",
    "mobilenet_acc = 0.8328\n",
    "print(f\"3. MobileNetV2 Accuracy: {mobilenet_acc:.4f}\")\n",
    "\n",
    "print(\"\\n--- Model Architecture Context ---\")\n",
    "print(f\"- MobileNetV2 Total Params: 2,270,794\")\n",
    "print(f\"- ResNet50V2 Total Params:  ~23,500,000\")\n",
    "\n",
    "print(\"\\n--- Exercise Insights ---\")\n",
    "print(f\"- Accuracy Gap: Transfer Learning (ResNet/MobileNet) outperformed Custom CNN by over 12-20%.\")\n",
    "print(f\"- Efficiency: MobileNetV2 achieved 83.28% accuracy with only 10% of ResNet's parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc879cdb",
   "metadata": {},
   "source": [
    "Exercise Discussion & Comparison\n",
    "\n",
    "1- Which model achieved the highest accuracy?\n",
    "The ResNet50V2 model achieved the highest accuracy at 91.62%. While MobileNetV2 performed impressively well with 83.28% in only 3 epochs, ResNet’s deeper architecture allows it to capture more complex features, leading to superior overall precision.\n",
    "\n",
    "2- Which model trained faster?\n",
    "MobileNetV2 was significantly faster during training. The training process was smooth and efficient, which is directly attributed to the much smaller number of parameters the system had to process compared to the other models.\n",
    "\n",
    "3- How might the architecture explain the differences?\n",
    "The differences in performance and speed are fundamentally rooted in the architectural design of each network:\n",
    "\n",
    "ResNet50V2: This is a massive architecture with approximately 23.5 million parameters. Its depth makes it highly accurate but also computationally \"heavy\" and slower to train.\n",
    "\n",
    "MobileNetV2: Designed for efficiency on mobile and embedded devices, it contains only about 2.27 million total parameters. It uses Depthwise Separable Convolutions, which drastically reduces the mathematical operations required while maintaining high accuracy.\n",
    "\n",
    "Custom CNN: This basic model had the lowest accuracy (70.99%) because it lacks the \"pre-trained knowledge\" that Transfer Learning models (ResNet and MobileNet) gain from being trained on the massive ImageNet dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
